{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2a61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126978e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxAccuracy = 0.00001\n",
    "\n",
    "def Agents(SLA, ServiceTime, CallsPerHour, AHT) :\n",
    "    \n",
    "    Count = 0\n",
    "    \n",
    "    try: \n",
    "    \n",
    "        if (SLA > 1): \n",
    "            SLA = 1\n",
    "        BirthRate = CallsPerHour\n",
    "        DeathRate = 3600 / AHT\n",
    "\n",
    "        TrafficRate = BirthRate / DeathRate\n",
    "\n",
    "        Erlangs = math.trunc((BirthRate * (AHT)) / 3600 + 0.5)\n",
    "\n",
    "        if (Erlangs < 1) : \n",
    "            NoAgents = 1\n",
    "        else : \n",
    "            NoAgents = math.floor(Erlangs)\n",
    "\n",
    "        Utilisation = TrafficRate / NoAgents\n",
    "\n",
    "        while (Utilisation >= 1) :\n",
    "            NoAgents = NoAgents + 1\n",
    "            Utilisation = TrafficRate / NoAgents\n",
    "\n",
    "        MaxIterate = NoAgents * 100\n",
    "\n",
    "        for index in range(1, MaxIterate+1) :\n",
    "            Utilisation = TrafficRate / NoAgents\n",
    "            if (Utilisation < 1) :\n",
    "                Server = NoAgents\n",
    "                C = ErlangC(Server, TrafficRate)\n",
    "\n",
    "                SLQueued = 1 - C * math.exp((TrafficRate - Server) * ServiceTime / AHT)\n",
    "                if (SLQueued < 0) : \n",
    "                    SLQueued = 0\n",
    "                if (SLQueued >= SLA): \n",
    "                    Count = MaxIterate\n",
    "                if (SLQueued > (1 - MaxAccuracy)): \n",
    "                    Count = MaxIterate\n",
    "            if (Count != MaxIterate) : \n",
    "                NoAgents = NoAgents + 1\n",
    "    except:\n",
    "        NoAgents = 0\n",
    "    return NoAgents\n",
    "\n",
    "\n",
    "def ErlangC(Servers, Intensity) :\n",
    "\n",
    "    try :\n",
    "        if ((Servers < 0) or (Intensity < 0)) :\n",
    "            return 0;\n",
    "        B = ErlangB(Servers, Intensity)\n",
    "        C = B / (((Intensity / Servers) * B) + (1 - (Intensity / Servers)))\n",
    "    except: \n",
    "        C = 0\n",
    "    return MinMax(C, 0, 1)\n",
    "\n",
    "\n",
    "def ErlangB(Servers, Intensity) :\n",
    "    try :\n",
    "        if ((Servers < 0) or (Intensity < 0)) :\n",
    "            return 0\n",
    "        MaxIterate = math.trunc(Servers)\n",
    "        Val = Intensity\n",
    "        Last = 1\n",
    "        for Count in range(MaxIterate+1) :\n",
    "            B = (Val * Last) / (Count + (Val * Last))\n",
    "            Last = B\n",
    "    except: \n",
    "        B = 0\n",
    "    return MinMax(B, 0, 1);\n",
    "\n",
    "\n",
    "def MinMax(val, _min, _max) :\n",
    "    result = val\n",
    "    if (val < _min): \n",
    "        result = _min;\n",
    "    if (val > _max): \n",
    "        result = _max;\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc6ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "all_df = pd.read_csv(\n",
    "    \"data-1641353182031.csv\",sep = ','\n",
    ")\n",
    "\n",
    "all_df = all_df.where((all_df[\"week\"] < 42))\n",
    "all_df = all_df.dropna()\n",
    "\n",
    "def forecast(n_df,_queue):\n",
    "    \n",
    "    df = n_df.where(n_df['QUEUE_NAME'] == _queue)\n",
    "    \n",
    "    if (df.agg({\"received\": np.sum})[\"received\"] < 5000): return False\n",
    "\n",
    "    group_by_week = df.groupby(\"week\").agg({\"received\": np.sum})\n",
    "\n",
    "    livestock3 = pd.Series(group_by_week['received'])\n",
    "\n",
    "    if (livestock3.count() < 8 ):\n",
    "        return False\n",
    "\n",
    "    fit3 = Holt(livestock3, damped_trend=True, initialization_method=\"estimated\").fit(\n",
    "        smoothing_level=0.8, smoothing_trend=0.2\n",
    "    )\n",
    "    fcast3 = fit3.forecast(50).rename(\"Additive damped trend\")\n",
    "\n",
    "    min_week = df[\"week\"].max()-4\n",
    "\n",
    "    four_week_data = df.where(df[\"week\"] > min_week)\n",
    "\n",
    "    received_group_wdate = df.groupby(\"week_day\").agg({\"received\": np.sum})\n",
    "\n",
    "    received_dis_wdate = received_group_wdate/df.agg({\"received\": np.sum})\n",
    "\n",
    "    received_group_hour = four_week_data.groupby([\"week_day\",\"hour\"]).agg({\"received\": np.sum})\n",
    "\n",
    "    received_dis_hour = received_group_hour/four_week_data.groupby(\"week_day\").agg({\"received\": np.sum})\n",
    "\n",
    "    received_dis_hour.rename(columns = {'received':'hour_dist'}, inplace = True)\n",
    "\n",
    "    received_dis_hour = received_dis_hour.reset_index()\n",
    "\n",
    "    answered_group_hour = four_week_data.groupby([\"week_day\",\"hour\"]).agg({\"answered\": np.sum})\n",
    "\n",
    "    time_group_hour = four_week_data.groupby([\"week_day\",\"hour\"]).agg({\"total\": np.sum})\n",
    "\n",
    "    series1 = pd.Series(time_group_hour['total']);\n",
    "    series2 = pd.Series(answered_group_hour[\"answered\"]);\n",
    "\n",
    "    aht_group_hour = series1.div(series2, fill_value=0).rename('aht').to_frame().reset_index()\n",
    "    \n",
    "    aht_group_hour = pd.merge(aht_group_hour,received_dis_wdate, on=\"week_day\",how=\"left\")\n",
    "    \n",
    "    aht_group_hour.rename(columns = {'received':'wd_dist'}, inplace = True)\n",
    "    \n",
    "    aht_group_hour = pd.merge(aht_group_hour, received_dis_hour, left_on=['week_day','hour'], right_on = ['week_day','hour'])\n",
    "    \n",
    "    aht_group_hour['global_dist'] = aht_group_hour['wd_dist'] * aht_group_hour['hour_dist'] \n",
    "    \n",
    "    result = pd.DataFrame({'datetime':pd.date_range(start = '2021/12/21', periods=60*24, freq='H')})\n",
    "\n",
    "    result['date'] = pd.to_datetime(result['datetime']).dt.date\n",
    "    result['hour'] = pd.to_datetime(result['datetime']).dt.hour\n",
    "    result = result.where((result[\"hour\"] < 19) & (result[\"hour\"] > 8) ).dropna()\n",
    "    result['week_day'] = pd.to_datetime(result['datetime']).dt.dayofweek\n",
    "    result = result.where(result[\"week_day\"] < 5).dropna()\n",
    "    result = pd.merge(result, aht_group_hour, left_on=['week_day','hour'] , right_on = ['week_day','hour'], how='left')\n",
    "    result.fillna(value=0, inplace=True)\n",
    "    \n",
    "    result['weeknumber'] = result['datetime'].dt.isocalendar().week\n",
    "    result['weeknumber_fake'] = result.apply(lambda row: ((row['weeknumber']+52) if row['weeknumber'] < 30 else row['weeknumber'] ) , axis = 1) \n",
    "    result['forecast_receive'] = result.apply(lambda row: (row['global_dist']*fcast3[row['weeknumber_fake']]) , axis = 1)\n",
    "    result['forecast_receive'] = result.apply(lambda row: (row['forecast_receive'] if row['forecast_receive'] > 0 else 0 ) , axis = 1)\n",
    "    result = result.drop(columns=['weeknumber_fake','datetime'])\n",
    "    result['agent_hours'] = result.apply(lambda row: (round(Agents(0.7, 30, row['forecast_receive'], row['aht']) / (1 - 0.15))) , axis = 1)\n",
    "    result['agent_hours'] = result.apply(lambda row: (row['agent_hours'] if (row['agent_hours']> 1) else 1 ), axis = 1)\n",
    "    result['aht'] = result['aht'].fillna(0)\n",
    "    result['aht'] = result.apply(lambda row: (round(row['aht'])) , axis = 1)\n",
    "    result['queue_name'] = _queue\n",
    "    result.to_csv(\"output/\"+_queue+\".csv\",sep = ';') \n",
    "    return True\n",
    "\n",
    "unprocessed_queue = []\n",
    "\n",
    "for x in all_df[\"QUEUE_NAME\"].unique():\n",
    "    if (x == 'nan') : continues\n",
    "    if (not forecast(all_df,x)): unprocessed_queue.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abd57b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhph\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot use heuristic method with less than 10 observations.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-edd7b52abde5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m \u001b[0mforecast_for_less_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munprocessed_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-edd7b52abde5>\u001b[0m in \u001b[0;36mforecast_for_less_queue\u001b[1;34m(m_df, list_queue)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlivestock3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_by_week\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'received'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     fit3 = Holt(livestock3, damped_trend=True, initialization_method=\"estimated\").fit(\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0msmoothing_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmoothing_trend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exponential, damped_trend, initialization_method, initial_level, initial_trend)\u001b[0m\n\u001b[0;32m   1722\u001b[0m     ):\n\u001b[0;32m   1723\u001b[0m         \u001b[0mtrend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"mul\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexponential\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"add\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1724\u001b[1;33m         super(Holt, self).__init__(\n\u001b[0m\u001b[0;32m   1725\u001b[0m             \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mtrend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, trend, damped_trend, seasonal, seasonal_periods, initialization_method, initial_level, initial_trend, initial_seasonal, use_boxcox, bounds, dates, freq, missing)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fixed_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_legacy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialization_method\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"heuristic\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"estimated\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_initialize_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py\u001b[0m in \u001b[0;36m_initialize_heuristic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[0mtrend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrend\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_trend\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mseasonal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseasonal\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_seasonal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m         lvl, trend, seas = _initialization_heuristic(\n\u001b[0m\u001b[0;32m    453\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseasonal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseasonal_periods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\exponential_smoothing\\initialization.py\u001b[0m in \u001b[0;36m_initialization_heuristic\u001b[1;34m(endog, trend, seasonal, seasonal_periods)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnobs\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         raise ValueError('Cannot use heuristic method with less than 10'\n\u001b[0m\u001b[0;32m     45\u001b[0m                          ' observations.')\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use heuristic method with less than 10 observations."
     ]
    }
   ],
   "source": [
    "def forecast_for_less_queue(m_df, list_queue): \n",
    "\n",
    "    df = m_df\n",
    "    boolean_series = df['QUEUE_NAME'].isin(list_queue)\n",
    "    \n",
    "    df = df[boolean_series]\n",
    "    \n",
    "    group_by_week = df.groupby(\"week\").agg({\"received\": np.sum})\n",
    "    \n",
    "    livestock3 = pd.Series(group_by_week['received'])\n",
    "\n",
    "    fit3 = Holt(livestock3, damped_trend=True, initialization_method=\"estimated\").fit(\n",
    "        smoothing_level=0.8, smoothing_trend=0.2\n",
    "    )\n",
    "    fcast3 = fit3.forecast(50).rename(\"Additive damped trend\")\n",
    "\n",
    "    min_week = df[\"week\"].max()-4\n",
    "\n",
    "    four_week_data = df.where(df[\"week\"] > min_week)\n",
    "\n",
    "    received_group_wdate = df.groupby(\"week_day\").agg({\"received\": np.sum})\n",
    "\n",
    "    received_dis_wdate = received_group_wdate/df.agg({\"received\": np.sum})\n",
    "    \n",
    "    received_dis_queue = df.groupby(\"QUEUE_NAME\").agg({\"received\": np.sum})/df.agg({\"received\": np.sum})\n",
    "\n",
    "    received_group_hour = four_week_data.groupby([\"week_day\",\"hour\"]).agg({\"received\": np.sum})\n",
    "\n",
    "    received_dis_hour = received_group_hour/four_week_data.groupby(\"week_day\").agg({\"received\": np.sum})\n",
    "\n",
    "    received_dis_hour.rename(columns = {'received':'hour_dist'}, inplace = True)\n",
    "\n",
    "    received_dis_hour = received_dis_hour.reset_index()\n",
    "\n",
    "    answered_group_hour = four_week_data.groupby([\"week_day\",\"hour\"]).agg({\"answered\": np.sum})\n",
    "\n",
    "    time_group_hour = four_week_data.groupby([\"week_day\",\"hour\"]).agg({\"total\": np.sum})\n",
    "\n",
    "    series1 = pd.Series(time_group_hour['total']);\n",
    "    series2 = pd.Series(answered_group_hour[\"answered\"]);\n",
    "\n",
    "    aht_group_hour = series1.div(series2, fill_value=0).rename('aht').to_frame().reset_index()\n",
    "    \n",
    "    aht_group_hour = pd.merge(aht_group_hour,received_dis_wdate, on=\"week_day\",how=\"left\")\n",
    "    aht_group_hour.rename(columns = {'received':'wd_dist'}, inplace = True)\n",
    "    aht_group_hour = pd.merge(aht_group_hour, received_dis_hour, left_on=['week_day','hour'], right_on = ['week_day','hour'])\n",
    "    aht_group_hour['global_dist'] = aht_group_hour['wd_dist'] * aht_group_hour['hour_dist'] \n",
    "    \n",
    "    result = pd.DataFrame({'datetime':pd.date_range(start = '2021/12/21', periods=60*24, freq='H')})\n",
    "\n",
    "    result['date'] = pd.to_datetime(result['datetime']).dt.date\n",
    "    result['hour'] = pd.to_datetime(result['datetime']).dt.hour\n",
    "    result = result.where((result[\"hour\"] < 19) & (result[\"hour\"] > 8) ).dropna()\n",
    "    result['week_day'] = pd.to_datetime(result['datetime']).dt.dayofweek\n",
    "    result = result.where(result[\"week_day\"] < 5).dropna()\n",
    "    result = pd.merge(result, aht_group_hour, left_on=['week_day','hour'] , right_on = ['week_day','hour'], how='left')\n",
    "    result.fillna(value=0, inplace=True)\n",
    "    \n",
    "    result['weeknumber'] = result['datetime'].dt.isocalendar().week\n",
    "    \n",
    "    result['weeknumber_fake'] = result.apply(lambda row: ((row['weeknumber']+52) if row['weeknumber'] < 30 else row['weeknumber'] ) , axis = 1) \n",
    "    result['forecast_receive'] = result.apply(lambda row: (row['global_dist']*fcast3[row['weeknumber_fake']]) , axis = 1)\n",
    "    result['forecast_receive'] = result.apply(lambda row: (row['forecast_receive'] if row['forecast_receive'] > 0 else 0 ) , axis = 1)\n",
    "    result = result.drop(columns=['weeknumber_fake','datetime'])\n",
    "    result['forecast_receive'] = result['forecast_receive'].fillna(0)\n",
    "    result['agent_hours'] = result.apply(lambda row: (round(Agents(0.7, 30, row['forecast_receive'], row['aht']) / (1 - 0.15))), axis = 1)\n",
    "    result['aht'] = result['aht'].fillna(0)\n",
    "    result['aht'] = result.apply(lambda row: (round(row['aht'])) , axis = 1)\n",
    "    for x in list_queue:\n",
    "        queue_result = result\n",
    "        queue_result['queue_name'] = x\n",
    "        print(x)\n",
    "        queue_result['aht'] = queue_result.apply(lambda row: (round(row['aht'])) , axis = 1)\n",
    "        queue_result['forecast_receive'] = queue_result.apply(lambda row: (round(row['forecast_receive']*received_dis_queue[\"received\"][x])) , axis = 1)\n",
    "        queue_result['agent_hours'] = result.apply(lambda row: (round(row['agent_hours']*received_dis_queue[\"received\"][x])), axis = 1)\n",
    "        queue_result['agent_hours'] = result.apply(lambda row: (row['agent_hours'] if (row['agent_hours']> 1) else 1 ), axis = 1)\n",
    "        name = x.replace(\"|\", \" \")\n",
    "        queue_result.to_csv(\"output/\"+name+\".csv\",sep = ';') \n",
    "    return True\n",
    "    \n",
    "forecast_for_less_queue(all_df, unprocessed_queue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081938e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
